{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Part 3 - Prediction\n",
    "\n",
    "This part of the project will be split into two parts. The first, undertaken in this notebook, will be a comparison of several classification algorithms tasked with predicting whether a seller in the marketplace will make a sale or not. The second part will be a prediction of the length of time it takes a seller's sale to sell, and this is found in the notebook time_to_sale_prediction.ipynb. \n",
    "\n",
    "This notebook is structured as follows:\n",
    "\n",
    "    1. Data Wrangling, Calculating Accuracy and Comparisons\n",
    "    2. Plots of the Model Evaluations\n",
    "    3. Confusion Matrix\n",
    "    4. Are we overfitting?\n",
    "    5. Summary\n",
    "\n",
    "# 1. Data Wrangling, Calculating Accuracy and Comparisons\n",
    "\n",
    "\n",
    "First let's try and run a simple prediction on whether a seller who comes to market will complete a sale or not. We'll be using the data from our large run generated from marketplace_predictions.py and located in the /exploration/data/. As a reminder, the references for the different parameter sets is in the first section of the notebook data_exploration_2.ipynb. It would be useful to have this open in a seperate tab for quick referral.\n",
    "\n",
    "Because we'll be dealing with large amounts of data, we'll first define a function to grab the data files. This is shown below and we'll use pandas to tidy up the data, rescale, and create extra features for z-scores and the exchange rate on the day advertised. We'll then evaluate the differences between Linear and Logistic Regression, Random Forest and K Nearest Neighbours in a matrix which will be output below as model_eval.\n",
    "\n",
    "## WARNING: Takes a long time to run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algo =  LinReg\n",
      "Evaluating run  0  of pset  1\n",
      "Evaluating run  1  of pset  1\n",
      "Evaluating run  2  of pset  1\n",
      "Evaluating run  3  of pset  1\n",
      "Evaluating run  4  of pset  1\n",
      "0.97345132444\n",
      "Evaluating run  0  of pset  2\n",
      "Evaluating run  1  of pset  2\n",
      "Evaluating run  2  of pset  2\n",
      "Evaluating run  3  of pset  2\n",
      "Evaluating run  4  of pset  2\n",
      "0.834960403704\n",
      "Evaluating run  0  of pset  3\n",
      "Evaluating run  1  of pset  3\n",
      "Evaluating run  2  of pset  3\n",
      "Evaluating run  3  of pset  3\n",
      "Evaluating run  4  of pset  3\n",
      "0.838926265315\n",
      "Evaluating run  0  of pset  4\n",
      "Evaluating run  1  of pset  4\n",
      "Evaluating run  2  of pset  4\n",
      "Evaluating run  3  of pset  4\n",
      "Evaluating run  4  of pset  4\n",
      "0.9748380023\n",
      "Evaluating run  0  of pset  5\n",
      "Evaluating run  1  of pset  5\n",
      "Evaluating run  2  of pset  5\n",
      "Evaluating run  3  of pset  5\n",
      "Evaluating run  4  of pset  5\n",
      "0.825642539281\n",
      "Evaluating run  0  of pset  6\n",
      "Evaluating run  1  of pset  6\n",
      "Evaluating run  2  of pset  6\n",
      "Evaluating run  3  of pset  6\n",
      "Evaluating run  4  of pset  6\n",
      "0.835137346036\n",
      "Evaluating run  0  of pset  7\n",
      "Evaluating run  1  of pset  7\n",
      "Evaluating run  2  of pset  7\n",
      "Evaluating run  3  of pset  7\n",
      "Evaluating run  4  of pset  7\n",
      "0.801361105485\n",
      "Algo =  LogReg\n",
      "Evaluating run  0  of pset  1\n",
      "Evaluating run  1  of pset  1\n",
      "Evaluating run  2  of pset  1\n",
      "Evaluating run  3  of pset  1\n",
      "Evaluating run  4  of pset  1\n",
      "0.999394735799\n",
      "Evaluating run  0  of pset  2\n",
      "Evaluating run  1  of pset  2\n",
      "Evaluating run  2  of pset  2\n",
      "Evaluating run  3  of pset  2\n",
      "Evaluating run  4  of pset  2\n",
      "0.860523449228\n",
      "Evaluating run  0  of pset  3\n",
      "Evaluating run  1  of pset  3\n",
      "Evaluating run  2  of pset  3\n",
      "Evaluating run  3  of pset  3\n",
      "Evaluating run  4  of pset  3\n",
      "0.839707548679\n",
      "Evaluating run  0  of pset  4\n",
      "Evaluating run  1  of pset  4\n",
      "Evaluating run  2  of pset  4\n",
      "Evaluating run  3  of pset  4\n",
      "Evaluating run  4  of pset  4\n",
      "0.99970870643\n",
      "Evaluating run  0  of pset  5\n",
      "Evaluating run  1  of pset  5\n",
      "Evaluating run  2  of pset  5\n",
      "Evaluating run  3  of pset  5\n",
      "Evaluating run  4  of pset  5\n",
      "0.822582721844\n",
      "Evaluating run  0  of pset  6\n",
      "Evaluating run  1  of pset  6\n",
      "Evaluating run  2  of pset  6\n",
      "Evaluating run  3  of pset  6\n",
      "Evaluating run  4  of pset  6\n",
      "0.833942102035\n",
      "Evaluating run  0  of pset  7\n",
      "Evaluating run  1  of pset  7\n",
      "Evaluating run  2  of pset  7\n",
      "Evaluating run  3  of pset  7\n",
      "Evaluating run  4  of pset  7\n",
      "0.807219174214\n",
      "Algo =  RF5\n",
      "Evaluating run  0  of pset  1\n",
      "Evaluating run  1  of pset  1\n",
      "Evaluating run  2  of pset  1\n",
      "Evaluating run  3  of pset  1\n",
      "Evaluating run  4  of pset  1\n",
      "1.0\n",
      "Evaluating run  0  of pset  2\n",
      "Evaluating run  1  of pset  2\n",
      "Evaluating run  2  of pset  2\n",
      "Evaluating run  3  of pset  2\n",
      "Evaluating run  4  of pset  2\n",
      "0.987466755602\n",
      "Evaluating run  0  of pset  3\n",
      "Evaluating run  1  of pset  3\n",
      "Evaluating run  2  of pset  3\n",
      "Evaluating run  3  of pset  3\n",
      "Evaluating run  4  of pset  3\n",
      "0.990150644737\n",
      "Evaluating run  0  of pset  4\n",
      "Evaluating run  1  of pset  4\n",
      "Evaluating run  2  of pset  4\n",
      "Evaluating run  3  of pset  4\n",
      "Evaluating run  4  of pset  4\n",
      "0.999983817461\n",
      "Evaluating run  0  of pset  5\n",
      "Evaluating run  1  of pset  5\n",
      "Evaluating run  2  of pset  5\n",
      "Evaluating run  3  of pset  5\n",
      "Evaluating run  4  of pset  5\n",
      "0.987763737702\n",
      "Evaluating run  0  of pset  6\n",
      "Evaluating run  1  of pset  6\n",
      "Evaluating run  2  of pset  6\n",
      "Evaluating run  3  of pset  6\n",
      "Evaluating run  4  of pset  6\n",
      "0.990821448584\n",
      "Evaluating run  0  of pset  7\n",
      "Evaluating run  1  of pset  7\n",
      "Evaluating run  2  of pset  7\n",
      "Evaluating run  3  of pset  7\n",
      "Evaluating run  4  of pset  7\n",
      "0.992019881928\n",
      "Algo =  RF10\n",
      "Evaluating run  0  of pset  1\n",
      "Evaluating run  1  of pset  1\n",
      "Evaluating run  2  of pset  1\n",
      "Evaluating run  3  of pset  1\n",
      "Evaluating run  4  of pset  1\n",
      "1.0\n",
      "Evaluating run  0  of pset  2\n",
      "Evaluating run  1  of pset  2\n",
      "Evaluating run  2  of pset  2\n",
      "Evaluating run  3  of pset  2\n",
      "Evaluating run  4  of pset  2\n",
      "0.98920908404\n",
      "Evaluating run  0  of pset  3\n",
      "Evaluating run  1  of pset  3\n",
      "Evaluating run  2  of pset  3\n",
      "Evaluating run  3  of pset  3\n",
      "Evaluating run  4  of pset  3\n",
      "0.992710631593\n",
      "Evaluating run  0  of pset  4\n",
      "Evaluating run  1  of pset  4\n",
      "Evaluating run  2  of pset  4\n",
      "Evaluating run  3  of pset  4\n",
      "Evaluating run  4  of pset  4\n",
      "0.999983817461\n",
      "Evaluating run  0  of pset  5\n",
      "Evaluating run  1  of pset  5\n",
      "Evaluating run  2  of pset  5\n",
      "Evaluating run  3  of pset  5\n",
      "Evaluating run  4  of pset  5\n",
      "0.989948597108\n",
      "Evaluating run  0  of pset  6\n",
      "Evaluating run  1  of pset  6\n",
      "Evaluating run  2  of pset  6\n",
      "Evaluating run  3  of pset  6\n",
      "Evaluating run  4  of pset  6\n",
      "0.994021043971\n",
      "Evaluating run  0  of pset  7\n",
      "Evaluating run  1  of pset  7\n",
      "Evaluating run  2  of pset  7\n",
      "Evaluating run  3  of pset  7\n",
      "Evaluating run  4  of pset  7\n",
      "0.994137122698\n",
      "Algo =  KNN5\n",
      "Evaluating run  0  of pset  1\n",
      "Evaluating run  1  of pset  1\n",
      "Evaluating run  2  of pset  1\n",
      "Evaluating run  3  of pset  1\n",
      "Evaluating run  4  of pset  1\n",
      "0.998344050129\n",
      "Evaluating run  0  of pset  2\n",
      "Evaluating run  1  of pset  2\n",
      "Evaluating run  2  of pset  2\n",
      "Evaluating run  3  of pset  2\n",
      "Evaluating run  4  of pset  2\n",
      "0.901782699626\n",
      "Evaluating run  0  of pset  3\n",
      "Evaluating run  1  of pset  3\n",
      "Evaluating run  2  of pset  3\n",
      "Evaluating run  3  of pset  3\n",
      "Evaluating run  4  of pset  3\n",
      "0.895169273834\n",
      "Evaluating run  0  of pset  4\n",
      "Evaluating run  1  of pset  4\n",
      "Evaluating run  2  of pset  4\n",
      "Evaluating run  3  of pset  4\n",
      "Evaluating run  4  of pset  4\n",
      "0.998074385158\n",
      "Evaluating run  0  of pset  5\n",
      "Evaluating run  1  of pset  5\n",
      "Evaluating run  2  of pset  5\n",
      "Evaluating run  3  of pset  5\n",
      "Evaluating run  4  of pset  5\n",
      "0.904048831267\n",
      "Evaluating run  0  of pset  6\n",
      "Evaluating run  1  of pset  6\n",
      "Evaluating run  2  of pset  6\n",
      "Evaluating run  3  of pset  6\n",
      "Evaluating run  4  of pset  6\n",
      "0.901473631931\n",
      "Evaluating run  0  of pset  7\n",
      "Evaluating run  1  of pset  7\n",
      "Evaluating run  2  of pset  7\n",
      "Evaluating run  3  of pset  7\n",
      "Evaluating run  4  of pset  7\n",
      "0.89437269378\n",
      "Algo =  KNN10\n",
      "Evaluating run  0  of pset  1\n",
      "Evaluating run  1  of pset  1\n",
      "Evaluating run  2  of pset  1\n",
      "Evaluating run  3  of pset  1\n",
      "Evaluating run  4  of pset  1\n",
      "0.998450776769\n",
      "Evaluating run  0  of pset  2\n",
      "Evaluating run  1  of pset  2\n",
      "Evaluating run  2  of pset  2\n",
      "Evaluating run  3  of pset  2\n",
      "Evaluating run  4  of pset  2\n",
      "0.899649854002\n",
      "Evaluating run  0  of pset  3\n",
      "Evaluating run  1  of pset  3\n",
      "Evaluating run  2  of pset  3\n",
      "Evaluating run  3  of pset  3\n",
      "Evaluating run  4  of pset  3\n",
      "0.878917182645\n",
      "Evaluating run  0  of pset  4\n",
      "Evaluating run  1  of pset  4\n",
      "Evaluating run  2  of pset  4\n",
      "Evaluating run  3  of pset  4\n",
      "Evaluating run  4  of pset  4\n",
      "0.998268574322\n",
      "Evaluating run  0  of pset  5\n",
      "Evaluating run  1  of pset  5\n",
      "Evaluating run  2  of pset  5\n",
      "Evaluating run  3  of pset  5\n",
      "Evaluating run  4  of pset  5\n",
      "0.89946804101\n",
      "Evaluating run  0  of pset  6\n",
      "Evaluating run  1  of pset  6\n",
      "Evaluating run  2  of pset  6\n",
      "Evaluating run  3  of pset  6\n",
      "Evaluating run  4  of pset  6\n",
      "0.882599474928\n",
      "Evaluating run  0  of pset  7\n",
      "Evaluating run  1  of pset  7\n",
      "Evaluating run  2  of pset  7\n",
      "Evaluating run  3  of pset  7\n",
      "Evaluating run  4  of pset  7\n",
      "0.873600423961\n",
      "      LinReg     LogReg        RF5       RF10       KNN5      KNN10\n",
      "1  0.9734513  0.9993947          1          1  0.9983441  0.9984508\n",
      "2  0.8349604  0.8605234  0.9874668  0.9892091  0.9017827  0.8996499\n",
      "3  0.8389263  0.8397075  0.9901506  0.9927106  0.8951693  0.8789172\n",
      "4   0.974838  0.9997087  0.9999838  0.9999838  0.9980744  0.9982686\n",
      "5  0.8256425  0.8225827  0.9877637  0.9899486  0.9040488   0.899468\n",
      "6  0.8351373  0.8339421  0.9908214   0.994021  0.9014736  0.8825995\n",
      "7  0.8013611  0.8072192  0.9920199  0.9941371  0.8943727  0.8736004\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import KFold,train_test_split,cross_val_score\n",
    "\n",
    "def get_accuracy_2(df,alg,predictors):\n",
    "    \"\"\"\n",
    "    Returns the accuracy of algorithm alg in predicting if a sale occurs or not\n",
    "    for sellers in dataframe df, using predictors in the input list predictors.\n",
    "    \"\"\"\n",
    "    X = df.reset_index()[predictors]\n",
    "    Y = df.reset_index()[\"Sold\"]\n",
    "  \n",
    "    # This time let's just let sklearn do the accuracy score for us...\n",
    "  #  return cross_val_score(alg, X, Y, cv = KFold(len(X), n_folds=10,\n",
    "  #                                         shuffle=True, random_state=4)).mean()\n",
    "    \n",
    "    train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.2,\n",
    "                                                    random_state=0)\n",
    "    # Train the model, and evaluate it\n",
    "    alg.fit(train_X, train_Y)\n",
    "    y_pred = alg.predict(test_X)\n",
    "    return accuracy_score(test_Y, np.round(y_pred))\n",
    "\n",
    "def get_df(param_set, run):\n",
    "    \"\"\"\n",
    "    Returns a wrangled dataframe for the input parameter set and run number\n",
    "    \"\"\"\n",
    "    # Import the data for sold and unsold traders\n",
    "    param_set = str(param_set) ;    run = str(run)\n",
    "    sold = pd.read_csv('../exploration/data/'+param_set+'_set_run_'+str(run)+'_sold.csv')\n",
    "    unsold = pd.read_csv('../exploration/data/'+param_set+'_set_run_'+str(run)+'_unsold.csv')\n",
    "    \n",
    "    ### Cast Day Tracker to list, trim data points within 'cutoff' days of simulation start/ends\n",
    "    sold['Day Tracker'] = sold['Day Tracker'].apply(lambda x: x.split(','));\n",
    "    sold = sold[sold['Day Advertised'] >=  8]; sold = sold[sold['Day Advertised'] <=  290]\n",
    "    unsold['Day Tracker'] = unsold['Day Tracker'].apply(lambda x: x.split(','));\n",
    "    unsold = unsold[unsold['Day Advertised'] >=  8]; unsold = unsold[unsold['Day Advertised'] <=  290]\n",
    "    \n",
    "    ## Create rates for each day for insertion into sold df\n",
    "    rates = pd.read_csv('../exploration/data/'+param_set+'_set_run_'+str(run)+'_rates.csv')\n",
    "    rate_dic = rates.to_dict()#['USD to EUR rate','USD sales','EUR sales']\n",
    "    \n",
    "    ### Get length of day tracker, save as new column - This is days spent in the market\n",
    "    sold['Lens'] = sold['Day Tracker'].apply(lambda x : len(x));\n",
    "    unsold['Lens'] = unsold['Day Tracker'].apply(lambda x : len(x));\n",
    "\n",
    "    # Create a column for the interbank rate for the day advertised\n",
    "    sold['Interbank'] = sold.apply(lambda row: rate_dic['USD to EUR rate'][row['Day Advertised']]\\\n",
    "                                   if(row['Currency']=='USD')\\\n",
    "                                   else 1.0/rate_dic['USD to EUR rate'][row['Day Advertised']],axis=1)\n",
    "    unsold['Interbank'] = unsold.apply(lambda row: rate_dic['USD to EUR rate'][row['Day Advertised']]\\\n",
    "                                   if(row['Currency']=='USD')\\\n",
    "                                   else 1.0/rate_dic['USD to EUR rate'][row['Day Advertised']],axis=1)\n",
    "\n",
    "    # Now do the z-scores\n",
    "    sd_denom = 100.0 # standard deviation denominator, set in marketplace.py default value = 100 yields true SD = RATE/100\n",
    "    sold.drop(['ID','Current Amount','Sale Tracker','Day Tracker',],inplace=True,axis=1);\n",
    "    unsold.drop(['ID','Current Amount','Sale Tracker','Day Tracker',],inplace=True,axis=1);\n",
    "\n",
    "    # Concatenate the sold and unsold DFs into one, \n",
    "    sold['Sold'] = 1; unsold['Sold'] = 0\n",
    "    df = pd.concat([sold,unsold], ignore_index=True)\n",
    "    \n",
    "    df['z-score'] = df.apply(lambda row: (row['Rate Offered']-row['Interbank'] )/ (row['Interbank']/sd_denom ),axis=1)\n",
    "\n",
    "    df['Currency'] = df.apply(lambda row: 0 if(row['Currency']=='EUR') else 1,axis=1)\n",
    "    \n",
    "    ## Rescale Features\n",
    "    df['Initial Amount'] = df.apply(lambda row: (row['Initial Amount'])/np.max(df['Initial Amount']),axis=1)\n",
    "    df['EUR sales'] =  df.apply(lambda row: np.log10(rate_dic['EUR sales'][row['Day Advertised']]),axis=1)\n",
    "    df['USD sales'] =  df.apply(lambda row: np.log10(rate_dic['USD sales'][row['Day Advertised']]),axis=1)\n",
    "    df['Day Advertised'] = df.apply(lambda row: (row['Day Advertised'])/np.max(df['Day Advertised']),axis=1)\n",
    "\n",
    "    return df\n",
    "    \n",
    "\n",
    "algos = [LinearRegression(),LogisticRegression(),\\\n",
    "         RandomForestClassifier(n_estimators=5, max_depth=None,min_samples_split=1, random_state=0),\\\n",
    "         RandomForestClassifier(n_estimators=15, max_depth=None,min_samples_split=1, random_state=0),\\\n",
    "         KNeighborsClassifier(n_neighbors=5),\\\n",
    "         KNeighborsClassifier(n_neighbors=15)]\n",
    "\n",
    "predictors = ['Currency', 'Initial Amount', 'Rate Offered',\\\n",
    "                  'z-score',\\\n",
    "                'Interbank','Day Advertised',\\\n",
    "#                  'EUR sales','USD sales'\\\n",
    "                ]\n",
    "\n",
    "cols = ['LinReg','LogReg','RF5','RF10','KNN5','KNN10']\n",
    "\n",
    "param_sets = range(1,8)\n",
    "runs = range(0,5)\n",
    "\n",
    "model_eval =  pd.DataFrame(index=None, columns=cols).fillna(0)\n",
    "\n",
    "for alg, col in zip(algos,cols):\n",
    "        print 'Algo = ', col\n",
    "        for param_set in param_sets:\n",
    "            avg = [0]*len(runs)\n",
    "            for run in runs:\n",
    "                print 'Evaluating run ', run, ' of pset ', param_set\n",
    "                df = get_df(param_set,run)\n",
    "                acc = get_accuracy_2(df, alg, predictors)\n",
    "                avg[run] = acc\n",
    "            mean = np.mean(np.array(avg))\n",
    "            model_eval.ix[str(param_set),col] = mean\n",
    "            print mean #, avg\n",
    "print model_eval\n",
    "\n",
    "#        print gamma, C ,get_accuracy(df, alg, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "####### SAVE TABLE #######\n",
    "model_eval.to_csv('classification_prediction_table.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Plots of the Model Evaluations\n",
    "\n",
    "We can plot the evaluation matrix to get it in a more visually appealing and useful form. Below is a discrete heat map and then a bar chart to allow us to more easily compare the various models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      LinReg     LogReg        RF5       RF10       KNN5      KNN10\n",
      "1  0.9734513  0.9993947          1          1  0.9983441  0.9984508\n",
      "2  0.8349604  0.8605234  0.9874668  0.9892091  0.9017827  0.8996499\n",
      "3  0.8389263  0.8397075  0.9901506  0.9927106  0.8951693  0.8789172\n",
      "4   0.974838  0.9997087  0.9999838  0.9999838  0.9980744  0.9982686\n",
      "5  0.8256425  0.8225827  0.9877637  0.9899486  0.9040488   0.899468\n",
      "6  0.8351373  0.8339421  0.9908214   0.994021  0.9014736  0.8825995\n",
      "7  0.8013611  0.8072192  0.9920199  0.9941371  0.8943727  0.8736004\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWkAAAD+CAYAAAD4b/QBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGyRJkiRJkiRJkiRJkiRJkqQp6P8ADuI3049HrKkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb47e410f10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "print model_eval\n",
    "plt.pcolor(model_eval,cmap=plt.cm.Blues)\n",
    "plt.yticks(np.arange(0.5, len(model_eval.index), 1), model_eval.index)\n",
    "plt.xticks(np.arange(0.5, len(model_eval.columns), 1), model_eval.columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes.AxesSubplot at 0x7fb47e410350>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2cAAAJNCAYAAAC1Cw2BAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XuYXWV9/+/3ZCKSSSYHQoAkmISEPhBQ2yJWpSqotdWq\npbYesKiIgiBQ8EC1Chaxiv2JFAG1CCJqPdRqRbF4wKL88NgqqGhtXEKYjAkBciKEBGIyme8fOZAA\nmZkke2aeTO77unIxe69n9v4ki0zmtddeaxIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKhK+0AWlVKe\nOHny5B9Mnjy5Z9myZT9+2LY/mTx58ucmT5782smTJ09dtmzZTYMzKgAAwMg1qr8FpZSOJBcl+eZ2\nllyS5K+S/HGSPy2lzG3deAAAAHuGfuMsydokL0xy98M3lFJmJ1neNM2ipml6k3wtyXNaOyIAAMDI\n12+cNU3T0zTN2u1sPiDJkq1u35NkaisGAwAA2JMM5MhZX3ofdrttFx8PAABgjzR6Fz//zmw8erbZ\ngUkWbW/xunXre0ePHtA1SIZc0zQ56RNvztgpnX2uWzJvcf7m1vWZ2tHR57pbly3Lojl/kYkT9u9z\n3b0r786573tFSil9ruvp6cntt9/e55rN5syZk/b2Ov+cAXZE7V+bAWBHtbW1bfeA1o7E2SMepGma\nBaWU8aWUmdkYZS9I8jfbe4AVK9bswNMNreXL78/YKZ3pnDaxz3Wr77kvUzvWZca4vr9RWLxmdVZP\n2D/7Tpre57oNGzbkZz/73yxffn+f67q7F+TqXy9K5wF9P96quxblvOcelTlzfq/Pdey6KVM6s2TJ\nquEeg0Fg39aj9q/NPT09SdrS3t7/G1FmzZrthbNB5u/uyGb/jmz270b9xlkp5alJrkyyX5L1pZRT\nk1ydZH7TNF9O8oYkn9u0/N+aprltsIYdiVauWpJ7bvt2Rt8/oc91v/zlwnTOPTUTps8coskA9lwD\n/dr8s18uzI8nvWiAL5zFC2cA9KnfOGua5kdJntDH9u8mOaqVQ+1pph0wITMP3KfPNXfetTLzhmge\nAAb+tblzynQvnAHQErt6QRAAAABaYFcvCAIAAIOqp6cnTdP0ex5o4vzO3ZH9+xBxBgBA1bq65ucj\nF351QFdaPe3vXuT8zt2M/fsQcQawFa/eAdRp4gCutMruy/7dSJwBbMWrdwDQGj09Penqmt/vuu7u\nBUMwze5BnAE8jFfvAIaGb95Hrp6entx003fy0wvekylj9u5z7a/vvTdrDntZv4+5YcOGPrcvXnxn\n3vnOv8/HPvapLfddeulFeelLX5GpU6c96uecccbrs3btg9l77zHp7e1NW1tb3vKWv8+sWQf1O89g\nEGfAHsE3ADCyeUvy7qmra35+8KYzM7Wjo891ty5blhxx8hBNRSt0dc3PRZ//eTqOeN2AP2dhth9f\na1bek5K2HZ7jzDPf0uf2tra2vOMd78pBB81Okvz0pzfn4osvzCWXfGSHn6sVxBnsBN8E7H58AwAj\nm7ck776mdnRkxrjOPtcsXrM6q4doHlqnY8J+GdfKd6KsXLLDn3LGGa/Pm9/8tnznO/+V1avvz29/\n251FixbmzDPfkqc+9ZE/qvmwww7PwoXdSZI77pifD37wwiRt6ejoyDnnvCvjxo3LBz94YX75y1/k\noINm57e/7c673vXeHHDA1F393SURZ7BTfBOwe/INAOx+duSot7ckAw/X1ta25b9LlizJhRdekv/+\n7x/my1/+jy1x1tvbu2X9d75zQw45ZG6S5IMfvDBvfes5mT79wHzpS1/Il7707/njP35mbr315/n4\nxz+d+fNvy4knHp/sxBG97RFnsBXfBADUxVFvoFWe+MQ/SJJMmTIlq1dvfPdTb29v3ve+87P33mOy\ndOmSTJ06Peee+64kya9+9b/5p3/6xyTJunXrMnfu4VmwoCuHH/6EJMns2Qdv91y2nSXOYCu+CQCo\nj6PeQCuMGjVqy8ebj5Ztfc7ZD37wvXz1q9dkn30mJ0nGjBmTyy776DaPccMN38qoUVsfKWvdUbMk\nGdX/EtizbP4moK9f/V11CACA3cPmUDvqqKdn7drf5Yc//F6S5OCDfy8/+tEPkiT/9V/fzM03/zjT\npx+YX/96XpKkq+uO3H334pbO4sgZAADQcmtW3tPix+r/KNUdd9ye449/yZbbixYt3PLx5vPP+vr4\nzDPfnHe84+wceeRTctZZZ+f9739vPv3pT2TvvffOeee9N52dnXnc42bk5JNPSCmHZNasg9Le3rrj\nXeIMAABoqVmzZuctL//9LLz4A5naMbbPtbcuW5qFc47NpL4utDbhgH5/ztnUqdNyww3ff9Rts2fP\n2erjg3PppZcnySPetjhr1kH57Gf/I0kyc+asfPjDV26zfd26dXnSk56cc855Vx544IEcf/xLMnny\nvn3OtSPEGQAA0FLt7e2ZMWNmejrGDuyc0QFcaG3pikWtHHGnPOYxj8m8eb/KF7/4+bS1teXkk9+w\nzblsu0qcAQAADNAb3/h3g/bYLggCAABQAXEGAABQAXEGAABQAXEGAABQARcEAQAAWqqnpyfd3Quy\neM3qftcueeCBrFh5d7/r+ruU/uLFd+ad7/z7fOxjnxrwnFu76qqP5lvf+mamTJmS3t7erF27Nq96\n1Yl55jOP2anH2xniDAAAaKmurvn50M+uytiXzRjA6slJ5mVp5m13xeolqzLz109u2XyPpq2tLS97\n2SvyV3/10iTJfffdlxNP/Js89alHZa+99hrU595MnAEAAC03dkpnOqdNbN0D/nrHP+X222/LxRe/\nP21tbeno6Mg555yfjo6OvPvd78zdd9+VJzzh9/Ptb38rX/rSdUmS3t7eLZ87fvz4TJ68b5YtW5oJ\nEybkggvOz6pV96enZ33e9Ka3Zs6cg/ONb1yXz33uX7Pffvtn4sRJOeKII/P8579wp3+L4gyAIdfT\n05Ourvn9ruvuXjAE0wAwUl1yyQdy+ulnZe7cw/O5z306X/jC53LIIXOzbt3v8tGPXp0f/OB7+fd/\n/+yjfm53d1dWrFiRKVP2y6c//Yk89alH5YUv/Mvcccf8XHrpRfnnf/5QrrjiI7nqqk9nzJgxedWr\nXp4jjjhyl+Yd8XHmGwCA+nR1zc9ZF16bjgn79blu2cL/y/TnD9FQAIw4CxbckblzD0+SHHHEkbn6\n6isyZsyYPOEJv58keepTj0p7e3uSjUfNvvCFf8uNN96Q1atXZ9263+W8896T0aNH5xe/uDUrV96b\nb37z60mStWvX5t57701Hx9hMmjQpSXLkkbv+tssRH2e+AQCoU8eE/TJu0vQ+16xZeXeSpUMzEAAj\n2rp1v0tb26j09vZm1KiNQdbW1pa2trYtH28+52zZsqU566w35OCDfy9Jstdej8mb3vTWHH7447c8\n3vLlyzJqVFtLZ9wjLqW/+RuAvn6N6dxnuMcEAABa6KCD5uSXv/xFkuSnP70lc+celunTD8y8eb9K\nkvzP//woPT09STYeOdt8ztnkyfvmz/7sBfn4xz+aJDnssMfnppu+kyS54475+fznP5MJEyZm5cqV\nWbVqVdaufTA//ektuzzviD9yBgAADL3VS1a19LH2HcC6O+64Pccf/5Itt9/61nNyxRUfTltbWzo7\nx+cd7zgvo0ePznXXXZvTTjspf/iHT8r48ROSbHsULUmOO+74nHDCcfnzP/+L/PVfvzwXXPCunH76\nydmwoSdvfONb097ente85qScfvpJOfDAGTn00LkZNWrXjn2JMwAAoKVmzZqdM/7gdVl48QcytWNs\nn2tvXbY0C+ccm0kT9u9z3YbOvn/O2dSp03LDDd9/xP2XXnr5Nrfvu+++vPCFx+boo5+dJUvuyY03\n3pAkee1rX7/Nusc85jH57Gf/Y8vt97zn/Y947EmTJuVDH7oy48ePz5vf/LeZPv1xfc7YH3EGAAC0\nVHt7e2bMmJmejrGZMa6zz7WL16zO6gn7Z99+zkNeumJRS2br6OjIt7/9rXz2s/+aDRs25Mwz37LT\nj/Xggw/mrLNOzd57j0kph+Txj3/CLs0mzgAAgD3G6NGjc/7572vJYz3veS/I8573gpY8VrKHXBAE\nAACgduIMAACgAuIMAACgAuIMAACgAi4IAgAAtFRPT0+6uxdk8ZrV/a5d8sADWbHy7n7XbdjQ96X0\nFy++M69+9XE59NC5SZJ169Zl9uw5Ofvst+dlLzs2++9/wJafQ9bW1pZLL708L3nJi7a5/7zz3pN9\n953S7yyDRZwBAAAt1dU1Pwsvvqjfn3GWJE+cvG+eeO/3k3u3v2bxmjX56bTn9vtYM2fOymWXfXTL\n7QsuOD/XX//1tLW15aKLLsvee++9zfrt3T9cxBkAANByUzs6+v0ZZzvipzvxOYcddngWLVrY55re\n3t6dG2gQOOcMAAAYcdavX5/vfvemlHJIku1H2Ac+cEFOO+2kXH75h4ZyvEflyBkAADAidHcvyN/+\n7SlJkttvvy2vfOUJecYzjskll1yUs88+c8u5ZZMm7ZN3v/t9OemkU/OUpxyVzs7OvP3tZ+fGG2/I\nMcc8Z9jmF2cAAMCIMGPGzC3nnJ177tty4IEzkmz/3LI/+7M/3/Lx0572x7n99tuGNc68rREAABhx\nTj/9rFx++WV58MEHH3X7/fffnzPOeH3Wrt24/Wc/uyVz5hw8lCM+giNnAABAyy1es6a1jzWx/3Vt\nbQ99PHXqtBx99LPzyU9elaTtEWvHjRuXo49+dk499bUZM6YjpRwyrEfNEnEGAAC02KxZs9P9prdk\n4cUf6Pdy+rcuW5qFc47NpAn797luQj8/52zq1Gm58spPbXPfKaecvs1/H+6lLz0uL33pcX0+7lAS\nZwAAQEu1t7dnxoyZ6ekY2+/l9BevWZ3VE/bPvpOm97lu6YpFrRyxSs45AwAAqIA4AwAAqIA4AwAA\nqIA4AwAAqIA4AwAAqICrNQIAAC3V09OT7u4FWbxmdb9rlzzwQFasvLvfdRv6uZT+4sV35tWvPi6H\nHjo3SbJu3brMnj0nZ5/99rzsZcdm//0PyKhRDx2buuyyj2bt2rV5//vfmwULuvKxjz10Gf5LL70o\nv/rV/6atLTnrrLNz6KGH9TtfK4gzAACgpbq65uc/P39rJs59Vbr6WzwzmdTPkntX3p3eATzvzJmz\nctllH91y+4ILzs/11389bW1tueiiy7L33ntvs/5f/uXSHHbY4Vmw4KEpf/rTm7Nw4cJcfvnHs2BB\nV973vnfn8ss/PoBn33XiDAAAaLmJA/jZZTtiIEfXHu6www7PokULt7v9lFPOyMqV9+brX79uy323\n3PKTPPOZxyTZGHurVt2XNWvWpKOjY4eff0c55wwAABhx1q9fn+9+96aUckiSpLf3kcfexowZ84j7\nly1bmokTJ265PXHipCxbtnRwh93EkTMAAGBE6O5ekL/921OSJLffflte+coT8oxnHJNLLrkoZ599\n5pZzziZOnJR//Md/GtBj9vb2pq2tbdBm3po4AwAARoQZM2ZuOefs3HPflgMPnJEk2z3nbPO2re27\n75QsW7Zsy+2lS5dk8uR9B3Hqh3hbIwAAMOKcfvpZufzyy/Lggw/2ue7hb2v8oz96am688YYkya9/\nPS9TpuyXMWPGDNqcW3PkDAAAaLl7d+ICHrv6WFsfBJs6dVqOPvrZ+eQnr0ry6G9LfOMbT8s999yd\nu+++K69+9cvz8pcfnxe84C9yyCFz84Y3vDajRrXnzW9+Wwt+BwMjzgAAgJaaNWt2XvjyJ2bhxR/I\n1I6xfa69ddnSLJxzbCZN2H+7ayZO2L/fn3M2deq0XHnlp7a575RTTt/mvw/3wQ9+5FHvP/XUM/p8\nrsEizgAAgJZqb2/PjBkz09MxNjPGdfa5dvGa1Vk9gMvuL12xqJUjVsk5ZwAAABUQZwAAABUQZwAA\nABUQZwAAABUQZwAAABVwtUYAAKClenp60t29IIvXrO537ZIHHsiKAfwcs/4upb948Z155zv/Ph/7\n2MbL6X/3uzfm85//bJ773Oflk5+8Kv/2b9dkr732SpJccMH5ee1rX5/e3t68/OV/mauv/mzmzDk4\nSfK1r301bW1tef7zX5ijj35KnvjEP9jyHJdc8i8ZNWrwjm+JMwAAoKW6uubnnts+k1knH9rv2ifn\ncXlyupN0b3fNnXetzH/f/IQBP//tt9+Wq666Ipde+i/53vduSmfn+HzhC5/L8cefsNWqtrS1JQcd\nNDuXX35ZLrzwko33bvWTrDs7O3PZZR8d8PPuKnEGAAC03LQDJmTmgfsM+fPee++9ee97z8u7331B\nxo+fkLa2trz4xS/JNdd8MS960Yszfvz4TSt7kySHHDI3a9c+mFtu+UmOOOLIIZ93a845AwAARoR1\n69bl3HPfmmc967mZMWPWlvsf+9jH5rjjjs+nPvXxR/28k08+LVdc8ZFH3L927e9y/vnn5g1veF0+\n//nPDNbYW4gzAABgRPjtb7vznOf8aa677tosWXLPNtue97wX5Oc/vyV33XXXlvt6ezcePTvwwMel\nlENyww3Xb/M5Z5zxxrztbefm4os/nOuv/0bmzfu/QZ1fnAEAACPC7Nlz8uIXvySnnnp6zj//3G0u\nItLW1pbXvvb1ufLKj2xz32YnnnhyPv3pT2T9+vVb7jv22L/K3nvvnb333jtPetKTM3/+bYM6vzgD\nAABGlGOOeU6mTz8wV1995Tb3P+1pT8/SpUty222/SdK25chZkkyatE+e8Yxj8pWvfClJ0t29IG9/\n+1uyYcOG9PT05Je/vDWzZ88Z1LldEAQAAGi5O+9aOeSPtdWBsLzxjX+Xk056VV75ytdss+bUU8/I\nKaecuGl92zbbXvGKV+XLX/6PJMmMGTMzY8asnHzyCRk9enSe/vRn5tBDD9v538QAiDMAAKClZs2a\nne6Dj0/XxR/I1I6xfa69ddnSLJxzbCZN2L/PdRM6+/45Z1OnTsuVV35qy+0xY8bkM5/54iPWzZ17\neG666X+23H7HO87b5nOuvfabW26/4Q1/2+dztpo4AwAAWqq9vT0zZsxMT8fYzBjX2efaxWtWZ/WE\n/bPvpOl9rlu6YlErR6ySc84AAAAqIM4AAAAqIM4AAAAqIM4AAAAqIM4AAAAqIM4AAICW6unpSXf3\ngixeszrd96/q89eSBx7IipV3Z+mKRX3+2rCh70vpL158Z0466dVbbn/3uzfmjDNen6985Uv5q796\nQX73u99t2XbBBefnrrsWZ/HiO/PMZ/5Rbr/9ti3bvva1r+brX//PJMl9963Mm998Rs49921btq9f\nvz7nn39uTjvtpJxxxutz552tu4qkS+kDAAAt1dU1P1f/elE6X3v2gD/nrj62rbprUfb92bIBP9bt\nt9+Wq666Ipde+i/53vduSmfn+HzhC5/L8cefsNWqtrS1JQcdNDuXX35ZLrzwko33bvWDqS+66P/L\nEUccmXnz/m/Lfd/61jcyfvz4nHfee/LjH/8oH/3oh3L++e8b8Gx9EWcAAEDLdR4wPROmz2zhIw4s\nzu699968973n5d3vviDjx09IW1tbXvzil+Saa76YF73oxRk/fvymlb1JkkMOmZu1ax/MLbf8JEcc\nceQ2j/X3f//OzJv3q23i7Oabf5znP/+FSZInPemP8r73/eOu/9Y28bZGAABgRFi3bl3OPfetedaz\nnpsZM2Ztuf+xj31sjjvu+HzqUx9/1M87+eTTcsUVH3nE/WPGjElvb+829y1fviwTJ05KkowatTGn\n1q9f35L5xRkAADAi/Pa33XnOc/401113bZYsuWebbc973gvy85/fkrvueugNlJvD68ADH5dSDskN\nN1w/oOd5eLC1ijgDAABGhNmz5+TFL35JTj319Jx//rnbXESkra0tr33t63PllR/Z5r7NTjzx5Hz6\n0594xFGwrdckyb77Tsny5RvfYrl+/fr09vZm9OjWnC0mzgAAgBHlmGOek+nTD8zVV1+5zf1Pe9rT\ns3Tpktx222+StG1zBGzSpH3yjGcck6985UvbfM7Dj5I9+clPyXe+819Jku9//6ZHnKe2K1wQBAAA\naLlVd7XuEvOr7lqUxw5g3dYHud74xr/LSSe9Kq985Wu2WXPqqWfklFNO3LR+26Nir3jFq/LlL/9H\nkmTDhg054YTj8uCDa7Nq1cq8+tUvzxlnvCnPec6f5sc//u+cdtpJ2WuvvXLOOe/ahd/ZtsQZAADQ\nUrNmzc6JhyzIwos/kKkdY/tce+uypVk459hMmrD/dtcckNHZ0Dmlz8eZOnVarrzyU1tujxkzJp/5\nzBcfsW7u3MNz003/s+X2O95x3jafc+2139xy+1//9d8f9bm2/pxWEmcAAEBLtbe3Z8aMmenpGJsZ\n4zr7XLt4zeqsnrB/9p00vc91S1e07khcrZxzBgAAUAFxBgAAUAFxBgAAUAFxBgAAUAFxBgAAUAFx\nBgAAUAFxBgAAUAFxBgAAUAFxBgAAUAFxBgAAUAFxBgAAUAFxBgAAUIHRwz0AAMBQ2bBhQ7q7Fwxo\n7axZs9Pe3j7IEwE8pN84K6VcnOQpSXqTnNU0zU+22nZsknOSrE3yb03TfHiwBgUA2FUrVy3JPbd9\nO6Pvn9DnujvvWpk8+x2ZM+f3hmgygH7irJRydJKDm6Y5qpRyaJKPJzlq07ZRSS5L8odJlif5Rinl\ny03TLBrkmWG34RVagPpMO2BCZh64z3CPAfAI/R05e3aSa5KkaZp5pZRJpZRxTdPcn2TfJPc2TbMs\nSUopNyb5kySfHLxxYffiFVoAGDpeFGV311+cHZDk5q1uL0kyNclvNn3cWUo5OMmCJM9IcuMgzAi7\nNa/QAsDQ8KIou7sdvSBIWzaee5amaXpLKa9L8okk9yS5a9P27Zo0qSOjRw/tKxQrVowb0uerwT77\njMuUKZ3DPcZuacWKcbljGJ63Z8OGrFy5ZED/v86ZM8crfTthMPatv2s7z9dmBsrX5ZFtMPbvQF8U\n9Xdy8Pm3d8f1F2d3ZuPRs82mJVm8+UbTNN9O8u0kKaVcmfT9579ixZqdm3IXLF9+/5A/53Bbvvz+\nLFmyarjH2C0N1/8vd9+zKh9f/Jt0dvf9d2TVXYty3nOP8krfThiMfevv2s7ztZmB8nV5ZBvOrwX+\nTg4+//buuP7i7Pok5ye5opRyRJJFTdOs3ryxlPK1JK9KsiHJc5K8bbAGhZGu84DpmTB95nCPAcAm\nvi4DQ63POGua5oellJtLKd9P0pPk9FLKCUlWNk3z5SRXZmPAjU5yTtM0ywd9YgAAgBGo33POmqZ5\n+8Pu+sVW267Jpqs5AgAAsPN29IIgAMTlmgGA1hNnADvB5ZoBYGjtCS+MijOAneRn2AHA0NkTXhgV\nZwAAwG5hpL8wOmq4BwAAAECcAQAAVEGcAQAAVECcAQAAVECcAQAAVECcAQAAVECcAQAAVECcAQAA\nVECcAQAAVECcAQAAVGD0cA8AAABDqWfDhnR3LxjQ2lmzZqe9vX2QJ4KNxBkAAHuUu+9ZlesWL0rn\nyr7XrbprUc57bjJnzu8NzWDs8cQZAAB7nM4DpmfC9JnDPQZswzlnAAAAFXDkDGAQOa8BABgocQYw\niJzXAAAMlDgDGGTOawAABsI5ZwAAABUQZwAAABUQZwAAABVwzhkAADBiDPRKyTVeJVmcAQAAI8ZA\nrpRc61WSxRkAADCi7K5XSnbOGQAAQAXEGQAAQAXEGQAAQAXEGQAAQAXEGQAAQAXEGQAAQAXEGQAA\nQAXEGQAAQAXEGQAAQAXEGQAAQAXEGQAAQAVGD/cAMBR6enrS1TW/33Xd3QuGYBoAAHgkccYeoatr\nft567T9k7JTOPtctmbc4b8leQzQVAAA8RJyxxxg7pTOd0yb2uWb1PfclWTc0AwEAwFaccwYAAFAB\ncQYAAFABcQYAAFABcQYAAFABcQYAAFABcQYAAFABcQYAAFABcQYAAFABcQYAAFABcQYAAFABcQYA\nAFABcQYAAFABcQYAAFABcQYAAFABcQYAAFABcQYAAFABcQYAAFABcQYAAFABcQYAAFABcQYAAFAB\ncQYAAFCB0cM9AMCj6enpSVfX/AGtS9rS3t73a03d3QtaNBkAwOAQZ0CVurrm56wLr03HhP36XLds\n4f9l4pF3ZOyUzj7XLZm3OG/JXq0cEQCgpcQZUK2OCftl3KTpfa5Zs/LujJ2yNJ3TJva5bvU99yVZ\n18LpAABayzlnAAAAFRBnAAAAFfC2RnZrA71ohItBAMCuG+i/u0kya9bstLe3D/JEMLKIM3ZrO3LR\niOnPH6KhAGCEGui/u6vvvStnH/eHmTFjZp/rvHgK2xJn7PYGetGIZOnQDAQAI9hA/9390M+uythF\nrqQLO0KcAQDQcmOndLqSLuwgFwQBAACogDgDAACogDgDAACogDgDAACogDgDAACogDgDAACogEvp\nAwAt1dPTk66u+QNaO2vW7LS3tw/yRAC7B3EGALRUV9f8nHXhtemYsF+f69asvCeX/N1fZM6c3xui\nyQDqJs4AgJbrmLBfxk2aPtxjAOxWnHMGAABQAUfOAIBh0bthQ7q7F/S5pr/tACOJOAMAhsUDq5bk\nQz/7RsYu6tzumiXzFuct2WsIpwIYPuIMABg2Y6d0pnPaxO1uX33PfUnWDd1AAMPIOWcAAAAVEGcA\nAAAVEGcAAAAVEGcAAAAVEGcAAAAVEGcAAAAVEGcAAAAVEGcAAAAVEGcAAAAVEGcAAAAVEGcAAAAV\nEGcAAAAVEGcAAAAVEGcAAAAVGD3cAwAAALuPnp6edHXN73ddd/eCIZhmZBFnAADAgHV1zc9br/2H\njJ3S2ee6JfMW5y3Za4imGhnEGQAAsEPGTulM57SJfa5Zfc99SdYNzUAjhHPOAAAAKtDvkbNSysVJ\nnpKkN8lZTdP8ZKttpyc5PklPkp80TfOmwRoUAABgJOvzyFkp5egkBzdNc1SS1yW5dKttE5KcneTp\nTdM8I8lhpZSnDOawAAAAI1V/R86eneSaJGmaZl4pZVIpZVzTNPcnWbvpV2cpZXWSjiTLBnVaAABg\nULgK4/Dxe5RYAAAQOklEQVTrL84OSHLzVreXJJma5DdN0zxYSnlXktuTPJjkX5umuW1QpgQAAAZV\nV9f8nHXhtemYsF+f65Yt/L9Mf/4QDbWH2dGrNbZl47lnKaWMT3JukpJkVZIbSilPaJrmF60dEQAA\nGAodE/bLuEnT+1yzZuXdSZYOzUB7mP7i7M5sPHq22bQkizd9PDfJ/KZplidJKeV7SY5Mst04mzSp\nI6NHt+/8tDthxYpxQ/p8Ndhnn3GZ0s/PnRgp7N+Ry74d2ezfkW1P27/27chm/45cNe7b/uLs+iTn\nJ7milHJEkkVN06zetK0rydxSyt5N0zyYjWH2tb4ebMWKNbs47o5bvvz+IX/O4bZ8+f1ZsmTVcI8x\nJOzfkcu+Hdns35FtT9u/9u3IZv+OXDXu2z7jrGmaH5ZSbi6lfD8bL5d/einlhCQrm6b5cinlwiTf\nKaWsT/L9pmm+NwQzAwAAjDj9nnPWNM3bH3bXL7badkWSK1o9FAAAwJ6mz59zBgAAwNAQZwAAABUQ\nZwAAABUQZwAAABUQZwAAABUQZwAAABUQZwAAABUQZwAAABUQZwAAABUQZwAAABUQZwAAABUQZwAA\nABUQZwAAABUQZwAAABUQZwAAABUQZwAAABUQZwAAABUQZwAAABUQZwAAABUQZwAAABUQZwAAABUQ\nZwAAABUQZwAAABUQZwAAABUQZwAAABUQZwAAABUQZwAAABUQZwAAABUQZwAAABUQZwAAABUQZwAA\nABUQZwAAABUQZwAAABUQZwAAABUQZwAAABUQZwAAABUQZwAAABUQZwAAABUQZwAAABUQZwAAABUQ\nZwAAABUQZwAAABUQZwAAABUQZwAAABUQZwAAABUQZwAAABUQZwAAABUQZwAAABUQZwAAABUQZwAA\nABUQZwAAABUQZwAAABUQZwAAABUQZwAAABUQZwAAABUQZwAAABUQZwAAABUQZwAAABUQZwAAABUQ\nZwAAABUQZwAAABUQZwAAABUQZwAAABUQZwAAABUQZwAAABUQZwAAABUQZwAAABUQZwAAABUQZwAA\nABUQZwAAABUQZwAAABUQZwAAABUQZwAAABUQZwAAABUQZwAAABUQZwAAABUQZwAAABUQZwAAABUQ\nZwAAABUQZwAAABUQZwAAABUQZwAAABUQZwAAABUQZwAAABUQZwAAABUQZwAAABUQZwAAABUQZwAA\nABUQZwAAABUQZwAAABUQZwAAABUQZwAAABUQZwAAABUQZwAAABUQZwAAABUQZwAAABUQZwAAABUQ\nZwAAABUQZwAAABUQZwAAABUQZwAAABUQZwAAABUQZwAAABUY3d+CUsrFSZ6SpDfJWU3T/GTT/dOS\nfGarpbOTvK1pmn8bjEEBAABGsj7jrJRydJKDm6Y5qpRyaJKPJzkqSZqmuTPJszata09yY5JrB3Va\nAACAEaq/tzU+O8k1SdI0zbwkk0op4x5l3YlJvtg0zZoWzwcAALBH6C/ODkiydKvbS5JMfZR1r0ty\nVauGAgAA2NPs6AVB2rLx3LMtSilPSzKvaZr7WzYVAADAHqa/C4LcmY1HzzablmTxw9a8MMm3BvJk\nkyZ1ZPTo9oFP1wIrVjzauzBHtn32GZcpUzqHe4whYf+OXPbtyGb/jmx72v61b0c2+3fkqnHf9hdn\n1yc5P8kVpZQjkixqmmb1w9YcmeSzA3myFSuG/pS05cv3vAN6y5ffnyVLVg33GEPC/h257NuRzf4d\n2fa0/Wvfjmz278hV477t822NTdP8MMnNpZTvJ/lgktNLKSeUUv5yq2VTk9wziDMCAACMeP3+nLOm\nad7+sLt+8bDtT2zpRAAAAHugHb0gCAAAAINAnAEAAFRAnAEAAFRAnAEAAFRAnAEAAFRAnAEAAFRA\nnAEAAFRAnAEAAFRAnAEAAFRAnAEAAFRAnAEAAFRAnAEAAFRAnAEAAFRAnAEAAFRAnAEAAFRAnAEA\nAFRAnAEAAFRAnAEAAFRAnAEAAFRAnAEAAFRAnAEAAFRAnAEAAFRAnAEAAFRAnAEAAFRAnAEAAFRA\nnAEAAFRAnAEAAFRAnAEAAFRAnAEAAFRAnAEAAFRAnAEAAFRAnAEAAFRAnAEAAFRAnAEAAFRAnAEA\nAFRAnAEAAFRAnAEAAFRAnAEAAFRAnAEAAFRAnAEAAFRAnAEAAFRAnAEAAFRAnAEAAFRAnAEAAFRA\nnAEAAFRAnAEAAFRAnAEAAFRAnAEAAFRAnAEAAFRAnAEAAFRAnAEAAFRAnAEAAFRAnAEAAFRAnAEA\nAFRAnAEAAFRAnAEAAFRAnAEAAFRAnAEAAFRAnAEAAFRAnAEAAFRAnAEAAFRAnAEAAFRAnAEAAFRA\nnAEAAFRAnAEAAFRAnAEAAFRAnAEAAFRAnAEAAFRAnAEAAFRAnAEAAFRAnAEAAFRAnAEAAFRAnAEA\nAFRAnAEAAFRAnAEAAFRAnAEAAFRAnAEAAFRAnAEAAFRAnAEAAFRAnAEAAFRAnAEAAFRAnAEAAFRA\nnAEAAFRAnAEAAFRAnAEAAFRAnAEAAFRAnAEAAFRAnAEAAFRAnAEAAFRAnAEAAFRAnAEAAFRAnAEA\nAFRAnAEAAFRAnAEAAFRAnAEAAFRAnAEAAFRAnAEAAFRAnAEAAFRAnAEAAFRAnAEAAFRAnAEAAFRA\nnAEAAFRAnAEAAFRgdH8LSikXJ3lKkt4kZzVN85Ottj0uyeeSPCbJLU3TvGGwBgUAABjJ+jxyVko5\nOsnBTdMcleR1SS592JKLklzYNM1TkvRsijUAAAB2UH9va3x2kmuSpGmaeUkmlVLGJUkpZVSSpyf5\n6qbtZzRN89tBnBUAAGDE6i/ODkiydKvbS5JM3fTxlCSrklxcSvluKeWCQZgPAABgj9DvOWcP05aN\n555t/nh6kg8mWZDkulLKnzdN87XtffKkSR0ZPbp9pwbdWStWjBvS56vBPvuMy5QpncM9xpCwf0cu\n+3Zks39Htj1t/9q3I5v9O3LVuG/7i7M7s/Ho2WbTkize9PHSJAuaprkjSUopNyQ5PMl242zFijU7\nP+lOWr78/iF/zuG2fPn9WbJk1XCPMSTs35HLvh3Z7N+RbU/bv/btyGb/jlw17tv+3tZ4fZKXJEkp\n5Ygki5qmWZ0kTdOsTzK/lHLwprVPSjJvsAYFAAAYyfo8ctY0zQ9LKTeXUr6fpCfJ6aWUE5KsbJrm\ny0nemOQTmy4OcmvTNF8d/JEBAABGnn7POWua5u0Pu+sXW227PckzWj0UAADAnqa/tzUCAAAwBMQZ\nAABABcQZAABABcQZAABABcQZAABABcQZAABABcQZAABABcQZAABABcQZAABABcQZAABABcQZAABA\nBcQZAABABcQZAABABcQZAABABcQZAABABcQZAABABcQZAABABcQZAABABcQZAABABcQZAABABcQZ\nAABABcQZAABABcQZAABABcQZAABABcQZAABABcQZAABABcQZAABABcQZAABABcQZAABABcQZAABA\nBcQZAABABcQZAABABcQZAABABcQZAABABcQZAABABcQZAABABcQZAABABcQZAABABcQZAABABcQZ\nAABABcQZAABABcQZAABABcQZAABABcQZAABABcQZAABABcQZAABABcQZAABABcQZAABABcQZAABA\nBcQZAABABcQZAABABcQZAABABcQZAABABcQZAABABcQZAABABcQZAABABcQZAABABcQZAABABcQZ\nAABABcQZAABABcQZAABABcQZAABABcQZAABABcQZAABABcQZAABABcQZAABABcQZAABABcQZAABA\nBcQZAABABcQZAABABcQZAABABcQZAABABcQZAABABcQZAABABcQZAABABcQZAABABcQZAABABcQZ\nAABABcQZAABABcQZAABABcQZAABABcQZAABABcQZAABABcQZAABABcQZAABABcQZAABABcQZAABA\nBcQZAABABcQZAABABcQZAABABcQZAABABcQZAABABcQZAABABcQZAABABcQZAABABcQZAABABcQZ\nAABABcQZAABABcQZAABABcQZAABABcQZAABABcQZAABABUb3t6CUcnGSpyTpTXJW0zQ/2WpbV5Lu\nJD2b7jq+aZo7B2FOAACAEa3POCulHJ3k4KZpjiqlHJrk40mO2mpJb5LnNU2zZhBnBAAAGPH6e1vj\ns5NckyRN08xLMqmUMu5ha9oGYzAAAIA9SX9xdkCSpVvdXpJk6sPWXF5K+W4p5X0tnQwAAGAPsqMX\nBGnLxrcybvbOJG9KckySx5dS/rpFcwEAALBZKeW8Usrrt7p9eyll7HbWvqGU8q4hGw4AAGAE6e/I\n2fVJXpIkpZQjkixqmmb1ptsTSin/fyllzKa1z0zyi0GbFAAAYATr92Iem84le2Y2Xi7/9CRHJFnZ\nNM2XSylnJjkxyf1Jfto0zZmDOSwAAAAAAAAAAAAAAAAAAAAAwC4ppUwa7hlojVLKIy6gU0p53HDM\nwuAppew73DMweEopzx7uGWi9UsroUsrMUsro4Z6FweFrM3uKfq/WyK4ppdzaNM0Th3sOdl4p5cVJ\nPphkbJLrkpzRNM2qTdu+0zTNs4ZzPnZeKeUFSf45yW+TvCnJp5OMTjIuyWlN01w3jOOxi0opJyTp\nzbb/1r0zybuTpGmaTw3HXOy6Usqlm68QXUr5kyRXJbkryX5J3tA0zTeGcz52TSnlz5Mc2zTNKZte\nULk6yaps/Np8RtM0/zmsA7JLSimrknwiyT82TXPPMI9THa8wtUAp5fQ+Nk8eskEYLG9P8odJViZ5\nXZJvlVKe1zTNvcM7Fi3wziTPTTIjyX8m+YumaX5eStl/021xtnv7hyTL8tB+bEvy2CQHDdtEtMoT\ntvr4vCTPappmfillvyRfSSLOdm/vTvLCTR+/Kw/t38lJvpaNX5/Zff0kyReSfLaU0p2NofaDpmnW\nD+tUlRBnrfHmJN9McvfD7m+LP+ORYH3TNMs3fXxFKeXuJN8opbywr09it/Bg0zTdSbpLKYuapvl5\nkjRNc3cp5YFhno1d9/gk5yZ5YpI3NU3TXUr5s6Zpzh/muWit5U3TzE+SpmnuKaX0DPdA7LLR2Xik\nLElWJOna9PHyR13NbqdpmpuS/Ekp5clJTsrG76/uT3J30zQvGN7phpdwaI0XJ7koG//xX7v1hlLK\nXw/PSLTQ90op1yV5WdM0q5um+Uop5cEk344jo7u7e0opZzdN84GmaY5KtpxH+OZsfKsju7GmaR5I\nck4p5dAkHy6l3JSkfZjHojUeX0r592x8EfTgUspLm6b5QinlvPgGfiS4MMktpZT/ysb9eU0p5YdJ\nnp2Nb2FlhGia5sdJfpwkpZRpSQ4Y3omGnzhrgaZpbi2lHJvk0Q7HnjzU89BaTdO8tZTyrCQPbnXf\nN0spP0ry8uGbjBZ4TR5668xm+yVZkI1vZ2UEaJpmXpIXlVJenWT+cM9DS7x0q497k/xm08e/ycYX\nS9mNNU3zmVLKN5L8SZKZSUZl4zmFr2ma5s5hHY5W+NdHu3PTvrV/AQAAAAAAAAAAAAAAAAAAAAAA\nAADYyv8DIt7FHzuRF94AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb47e950810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_eval.plot(kind='bar',ylim=([0.5,1]),figsize=(15,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 3. Confusion Matrix\n",
    "\n",
    "We can check how well the classification works using a confusion matrix - this will give us a test on the number of false positives/false negatives that our prediction algorithm gives. This is useful as we know from our data exploration that there will be many more sellers than non-sellers, so if our algorithms are not very accurate in predicting non-sellers this could be missed by just taking the face value of the accuracy score above. The code default below computes a confusion matrix using Random Forest with 15 estimators on parameter set 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.994125805662\n",
      "Predicted   0.0   1.0    All\n",
      "Actual                      \n",
      "0          2842    45   2887\n",
      "1            27  9343   9370\n",
      "All        2869  9388  12257\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pandas as pd ; import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "%matplotlib inline  \n",
    "\n",
    "def get_df(param_set, run):\n",
    "    param_set = str(param_set) ;    run = str(run)\n",
    "    sold = pd.read_csv('../exploration/data/'+param_set+'_set_run_'+str(run)+'_sold.csv')\n",
    "    unsold = pd.read_csv('../exploration/data/'+param_set+'_set_run_'+str(run)+'_unsold.csv')\n",
    "    \n",
    "    ### Cast Day Tracker to list, trim data points within 'cutoff' days of simulation start/ends\n",
    "    sold['Day Tracker'] = sold['Day Tracker'].apply(lambda x: x.split(','));\n",
    "    sold = sold[sold['Day Advertised'] >=  8]; sold = sold[sold['Day Advertised'] <=  290]\n",
    "    unsold['Day Tracker'] = unsold['Day Tracker'].apply(lambda x: x.split(','));\n",
    "    unsold = unsold[unsold['Day Advertised'] >=  8]; unsold = unsold[unsold['Day Advertised'] <=  290]\n",
    "    ## Create rates for each day for insertion into sold df\n",
    "    rates = pd.read_csv('../exploration/data/'+param_set+'_set_run_'+str(run)+'_rates.csv')\n",
    "    rate_dic = rates.to_dict()#['USD to EUR rate','USD sales','EUR sales']\n",
    "    ### Get length of day tracker, save as new column - This is days spent in the market\n",
    "    sold['Lens'] = sold['Day Tracker'].apply(lambda x : len(x));\n",
    "    unsold['Lens'] = unsold['Day Tracker'].apply(lambda x : len(x));\n",
    "\n",
    "    # Create a column for the interbank rate for the day advertised\n",
    "    sold['Interbank'] = sold.apply(lambda row: rate_dic['USD to EUR rate'][row['Day Advertised']]\\\n",
    "                                   if(row['Currency']=='USD')\\\n",
    "                                   else 1.0/rate_dic['USD to EUR rate'][row['Day Advertised']],axis=1)\n",
    "    unsold['Interbank'] = unsold.apply(lambda row: rate_dic['USD to EUR rate'][row['Day Advertised']]\\\n",
    "                                   if(row['Currency']=='USD')\\\n",
    "                                   else 1.0/rate_dic['USD to EUR rate'][row['Day Advertised']],axis=1)\n",
    "\n",
    "    # Now do the z-scores\n",
    "    sd_denom = 100.0 # standard deviation denominator, set in marketplace.py default value = 100 yields true SD = RATE/100\n",
    "    sold.drop(['ID','Current Amount','Sale Tracker','Day Tracker',],inplace=True,axis=1);\n",
    "    unsold.drop(['ID','Current Amount','Sale Tracker','Day Tracker',],inplace=True,axis=1);\n",
    "\n",
    "    sold['Sold'] = 1; unsold['Sold'] = 0\n",
    "    df = pd.concat([sold,unsold], ignore_index=True)\n",
    "    \n",
    "    df['z-score'] = df.apply(lambda row: (row['Rate Offered']-row['Interbank'] )/ (row['Interbank']/sd_denom ),axis=1)\n",
    "\n",
    "    df['Currency'] = df.apply(lambda row: 0 if(row['Currency']=='EUR') else 1,axis=1)\n",
    "    \n",
    "    ## Rescale Features\n",
    "    df['Initial Amount'] = df.apply(lambda row: (row['Initial Amount'])/np.max(df['Initial Amount']),axis=1)\n",
    "    df['EUR sales'] =  df.apply(lambda row: np.log10(rate_dic['EUR sales'][row['Day Advertised']]),axis=1)\n",
    "    df['USD sales'] =  df.apply(lambda row: np.log10(rate_dic['USD sales'][row['Day Advertised']]),axis=1)\n",
    "    df['Day Advertised'] = df.apply(lambda row: (row['Day Advertised'])/np.max(df['Day Advertised']),axis=1)\n",
    "\n",
    "    return df\n",
    "    \n",
    "param_set = 7\n",
    "run = 1\n",
    "\n",
    "df  = get_df(param_set,run)\n",
    "\n",
    "predictors = ['Currency', 'Initial Amount', 'Rate Offered',\\\n",
    "                  'z-score',\\\n",
    "                'Interbank','Day Advertised',\\\n",
    "#                  'EUR sales','USD sales'\\\n",
    "                ]\n",
    "\n",
    "X = df.reset_index()[predictors]\n",
    "Y = df.reset_index()[\"Sold\"]\n",
    "\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.2,\n",
    "                                                    random_state=0)\n",
    "\n",
    "# Train the model, and evaluate it\n",
    "alg = RandomForestRegressor(n_estimators=15)\n",
    "#alg = KNeighborsClassifier(n_neighbors=15)\n",
    "alg.fit(train_X, train_Y)\n",
    "y_pred = alg.predict(test_X)\n",
    "print accuracy_score(test_Y, np.round(y_pred))\n",
    "#test_Y = pd.Series(test_Y, name='Actual')\n",
    "#y_pred = pd.Series( np.round(y_pred), name='Predicted')\n",
    "# Make normalised confusion matrix\n",
    "cm = pd.crosstab(test_Y, np.round(y_pred), rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "print cm\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems our classification algorithm does a pretty good job of identifying sellers and non-sellers correctly, with very few misclassifications. However, an accuracy of 99.4% seems extremely high and should be viewed with suspicion - we are probably overfitting our prediction algorithm to the available data. \n",
    "\n",
    "# 4. Are we overfitting?\n",
    "\n",
    "Basically, yes. While it does seem probable that the underlying mathematical rules of the marketplace may make the behaviour of some parameter sets easy to predict - for example in the constant exchange rate model (set 1) there is very little randomness in the system. Parameter set 7 uses the GBM model with a varying number of buyers and sellers on each market iteration, as well as different currency amounts used. Therefore we shouldn't expect to get such a good prediction rate, and so we are most likely overfitting, especially with the Random Forest model (see plots in previous sections - this algorithm scores consistently over 95% accuracy).\n",
    "\n",
    "Below is a short piece of code using the Random Forest algorithm, however the algorithm has been tweaked to correct for overfitting. Several things can be done to correct for this:\n",
    "    - increase the number of trees (n_estimators)\n",
    "    - reduce the number of features assigned to each tree (max_features)\n",
    "    - reduce the max depth of the trees, reducing the tree complexity (max_depth)\n",
    "    - increasing minimum number of samples required to split a node (min_samples_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prepare data for cell below\n",
    "param_set = 7 ; run = 1 ; df  = get_df(param_set,run)\n",
    "predictors = ['Currency', 'Initial Amount', 'Rate Offered', 'z-score', 'Interbank','Day Advertised']\n",
    "X = df.reset_index()[predictors] ; Y = df.reset_index()[\"Sold\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.860455916531\n",
      "101 0.867527073135\n",
      "201 0.847994857341\n",
      "301 0.846363051971\n",
      "401 0.851159570786\n",
      "501 0.843544479058\n",
      "601 0.837511744054\n",
      "701 0.834693171142\n",
      "801 0.825396825397\n",
      "901 0.831083419868\n"
     ]
    }
   ],
   "source": [
    "# Test for overfitting...\n",
    "for md in range(1,1000,100):\n",
    "    train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.33)\n",
    "    # Train the model, and evaluate it\n",
    "    alg = RandomForestRegressor(n_estimators=50,\n",
    "                                max_features = 3,\n",
    "                                max_depth = 5,\n",
    "                                min_samples_leaf = md)\n",
    "    alg.fit(train_X, train_Y)\n",
    "    y_pred = alg.predict(test_X)\n",
    "    print md , accuracy_score(test_Y, np.round(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By experimenting with these various inputs a more reasonable prediction score can be obtained. A score around 80%-90% is considered to be optimal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 5. Summary\n",
    "\n",
    "In this notebook we have compared and contrasted several machine learning algorithms on the task of predicting whether a seller in our simulated marketplace will sell or not. We also looked at the phenomenon of overfitting of the Random Forest algorithm and steps taken to resolve this issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
